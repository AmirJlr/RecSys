{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxwrRZSrMRebsg7TC+CqkX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmirJlr/RecSys/blob/master/02_Movie_Recommender(Retrieval_Ranking).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Recommender (Retrieval with Genres + Ranking)\n",
        "\n",
        "## Recap: Two-Stage Recommender\n",
        "\n",
        "- #### **Retrieval Stage**: Quickly selects a subset of hundreds of potentially relevant candidates from the entire catalog (millions of items). Its goal is efficiency and recall.\n",
        "\n",
        "\n",
        "- #### **Ranking Stage**: Takes the candidates from the retrieval stage and scores/orders them more precisely. It can use more features and a more complex model because it only operates on a small set of items. Its goal is precision."
      ],
      "metadata": {
        "id": "ILhpRd1uUB1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Data Preparation"
      ],
      "metadata": {
        "id": "4GRyr6R5TkUM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "adCuPddzTF62"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade scann"
      ],
      "metadata": {
        "id": "jbwFpCUxTOuW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "Ekn5yxXqTex9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ratings and movies\n",
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
        "\n",
        "# Select relevant features\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"user_rating\": x[\"user_rating\"]\n",
        "})\n",
        "\n",
        "movies = movies.map(lambda x: x[\"movie_title\"])"
      ],
      "metadata": {
        "id": "JyCJYKAXTvRP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vocabularies for user IDs and movie titles\n",
        "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
        "user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
        "\n",
        "movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
        "movie_titles_vocabulary.adapt(movies)"
      ],
      "metadata": {
        "id": "rDL8mospVGV3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. The Retrieval Model\n",
        "\n",
        "The retrieval stage is responsible for quickly selecting a smaller subset of relevant candidates from the entire movie catalog. We'll build a two-tower model where one tower embeds users and the other embeds movies."
      ],
      "metadata": {
        "id": "ALx7Bdx8l-zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MovieLensRetrievalModel(tfrs.Model):\n",
        "\n",
        "  def __init__(self, user_model, movie_model, task):\n",
        "    super().__init__()\n",
        "    self.user_model = user_model\n",
        "    self.movie_model = movie_model\n",
        "    self.task = task\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "    return self.task(user_embeddings, positive_movie_embeddings)\n",
        "\n",
        "\n",
        "\n",
        "# User and Movie Towers\n",
        "embedding_dimension = 32\n",
        "\n",
        "user_model = tf.keras.Sequential([\n",
        "    user_ids_vocabulary,\n",
        "    tf.keras.layers.Embedding(user_ids_vocabulary.vocabulary_size(), embedding_dimension)\n",
        "])\n",
        "\n",
        "\n",
        "movie_model = tf.keras.Sequential([\n",
        "    movie_titles_vocabulary,\n",
        "    tf.keras.layers.Embedding(movie_titles_vocabulary.vocabulary_size(), embedding_dimension)\n",
        "])\n",
        "\n",
        "# The retrieval task\n",
        "retrieval_task = tfrs.tasks.Retrieval(\n",
        "    metrics=tfrs.metrics.FactorizedTopK(\n",
        "        candidates=movies.batch(128).map(movie_model)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "JSFEhz8dWhkR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_model = MovieLensRetrievalModel(user_model, movie_model, retrieval_task)\n",
        "\n",
        "retrieval_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "\n",
        "# Train the retrieval model\n",
        "history_retrieval = retrieval_model.fit(ratings.batch(4096), epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo99xow4mNsN",
        "outputId": "39e5e4a2-e956-4367-dbdc-23ef1ab3953c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "25/25 [==============================] - 18s 647ms/step - factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0054 - factorized_top_k/top_10_categorical_accuracy: 0.0124 - factorized_top_k/top_50_categorical_accuracy: 0.0860 - factorized_top_k/top_100_categorical_accuracy: 0.1703 - loss: 31878.1781 - regularization_loss: 0.0000e+00 - total_loss: 31878.1781\n",
            "Epoch 2/3\n",
            "25/25 [==============================] - 14s 563ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0142 - factorized_top_k/top_10_categorical_accuracy: 0.0315 - factorized_top_k/top_50_categorical_accuracy: 0.1533 - factorized_top_k/top_100_categorical_accuracy: 0.2753 - loss: 30745.7036 - regularization_loss: 0.0000e+00 - total_loss: 30745.7036\n",
            "Epoch 3/3\n",
            "25/25 [==============================] - 15s 563ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0182 - factorized_top_k/top_10_categorical_accuracy: 0.0388 - factorized_top_k/top_50_categorical_accuracy: 0.1763 - factorized_top_k/top_100_categorical_accuracy: 0.3034 - loss: 30292.5062 - regularization_loss: 0.0000e+00 - total_loss: 30292.5062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exporting Embeddings for ANN: After training, we'll use the movie_model to generate embeddings for all movies. These embeddings will be used to build the ScaNN index."
      ],
      "metadata": {
        "id": "ddzZdC0YmZK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Approximate Nearest Neighbor (ANN) Search with ScaNN\n",
        "Once we have movie embeddings, we can build a ScaNN index for fast approximate lookups."
      ],
      "metadata": {
        "id": "8ThrRg7vmdVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the ScaNN index\n",
        "scann_index = tfrs.layers.factorized_top_k.ScaNN(num_leaves=100, num_leaves_to_search=10, k=10) # k is num_recos\n",
        "\n",
        "scann_index.index_from_dataset(\n",
        "    tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(movie_model)))\n",
        ")\n",
        "\n",
        "# Get recommendations for a user\n",
        "def get_retrieval_recommendations_scann(user_id_str, num_recs=10):\n",
        "    query_embedding = user_model(tf.constant([user_id_str]))\n",
        "    scores, titles = scann_index(query_embedding) # Returns (scores, ids)\n",
        "    print(f\"ScaNN Retrieval Recommendations for user {user_id_str}:\\n {titles[0, :num_recs].numpy()}\")\n",
        "    return titles[0, :num_recs]"
      ],
      "metadata": {
        "id": "m3fNLtmVmYFJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "retrieved_candidates_scann = get_retrieval_recommendations_scann(\"42\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm6A_MLrmsnC",
        "outputId": "b9676d1d-e75c-4596-df87-439e49d8cad3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ScaNN Retrieval Recommendations for user 42:\n",
            " [b'Client, The (1994)' b'Old Yeller (1957)'\n",
            " b'Angels in the Outfield (1994)' b'Rudy (1993)'\n",
            " b\"Kid in King Arthur's Court, A (1995)\"\n",
            " b'Bridges of Madison County, The (1995)'\n",
            " b'Man Without a Face, The (1993)' b'Circle of Friends (1995)'\n",
            " b'Legends of the Fall (1994)' b'Fried Green Tomatoes (1991)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. The Ranking Model\n",
        "\n",
        "The ranking model takes the candidates selected by the retrieval (and ANN) stage and scores them to produce a final, ordered list of recommendations. It typically uses more features than the retrieval model to achieve higher precision."
      ],
      "metadata": {
        "id": "MeR45cWem1sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MovieLensRankingModel(tfrs.Model):\n",
        "    def __init__(self, user_model, movie_model, task):\n",
        "        super().__init__()\n",
        "        self.user_model = user_model\n",
        "        self.movie_model = movie_model\n",
        "        self.task = task\n",
        "\n",
        "        # Ranking specific layers\n",
        "        self.rating_model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(1) # Predict the rating\n",
        "        ])\n",
        "\n",
        "\n",
        "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "        user_embedding = self.user_model(features[\"user_id\"])\n",
        "        movie_embedding = self.movie_model(features[\"movie_title\"])\n",
        "        return self.rating_model(tf.concat([user_embedding, movie_embedding], axis=1))\n",
        "\n",
        "\n",
        "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "        labels = features.pop(\"user_rating\")\n",
        "        rating_predictions = self(features)\n",
        "        return self.task(labels=labels, predictions=rating_predictions)\n"
      ],
      "metadata": {
        "id": "i9IUuG-FmtY2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for ranking (user_id, movie_title, user_rating)\n",
        "ranking_data = ratings.map(lambda x: {\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_rating\": x[\"user_rating\"]\n",
        "})\n",
        "\n",
        "# Ranking Task (e.g., Mean Squared Error for rating prediction)\n",
        "ranking_task = tfrs.tasks.Ranking(\n",
        "    loss=tf.keras.losses.MeanSquaredError(),\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        ")"
      ],
      "metadata": {
        "id": "kSNw3lIGnQZm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-use user and movie models (or define new, potentially more complex ones)\n",
        "# For simplicity, we reuse the retrieval ones here, but in practice,\n",
        "# ranking models might have different architectures or feature inputs.\n",
        "\n",
        "ranking_user_model = user_model    # Or a new user model for ranking\n",
        "ranking_movie_model = movie_model  # Or a new movie model for ranking\n",
        "\n",
        "\n",
        "ranking_model = MovieLensRankingModel(ranking_user_model, ranking_movie_model, ranking_task)\n",
        "\n",
        "ranking_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "\n",
        "# Train the ranking model\n",
        "history_ranking = ranking_model.fit(ranking_data.batch(4096), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uymkfNb-n22x",
        "outputId": "ed1a57b8-b795-4a9c-ef55-d71a561f5c2b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 5s 138ms/step - root_mean_squared_error: 2.4278 - loss: 5.6000 - regularization_loss: 0.0000e+00 - total_loss: 5.6000\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 2s 62ms/step - root_mean_squared_error: 1.0108 - loss: 1.0201 - regularization_loss: 0.0000e+00 - total_loss: 1.0201\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 1s 57ms/step - root_mean_squared_error: 0.9954 - loss: 0.9894 - regularization_loss: 0.0000e+00 - total_loss: 0.9894\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 1s 57ms/step - root_mean_squared_error: 0.9863 - loss: 0.9713 - regularization_loss: 0.0000e+00 - total_loss: 0.9713\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 1s 59ms/step - root_mean_squared_error: 0.9788 - loss: 0.9566 - regularization_loss: 0.0000e+00 - total_loss: 0.9566\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9721 - loss: 0.9434 - regularization_loss: 0.0000e+00 - total_loss: 0.9434\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 1s 57ms/step - root_mean_squared_error: 0.9658 - loss: 0.9312 - regularization_loss: 0.0000e+00 - total_loss: 0.9312\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 2s 96ms/step - root_mean_squared_error: 0.9598 - loss: 0.9196 - regularization_loss: 0.0000e+00 - total_loss: 0.9196\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9541 - loss: 0.9086 - regularization_loss: 0.0000e+00 - total_loss: 0.9086\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9487 - loss: 0.8984 - regularization_loss: 0.0000e+00 - total_loss: 0.8984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the Ranking Model with ScaNN Candidates:"
      ],
      "metadata": {
        "id": "f2mbF7bboPme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ranked_recommendations(user_id_str, retrieved_movie_titles):\n",
        "    # Create features for the ranking model\n",
        "    num_retrieved_movies = retrieved_movie_titles.shape[0]\n",
        "    ranking_features = {\n",
        "        \"user_id\": tf.constant([user_id_str] * num_retrieved_movies),\n",
        "        \"movie_title\": retrieved_movie_titles\n",
        "    }\n",
        "\n",
        "    # Get predicted ratings\n",
        "    predicted_ratings = ranking_model(ranking_features)\n",
        "\n",
        "    # Sort movies by predicted rating\n",
        "    sorted_indices = tf.argsort(predicted_ratings, axis=0, direction='DESCENDING').numpy().flatten()\n",
        "    ranked_movie_titles = tf.gather(retrieved_movie_titles, sorted_indices).numpy()\n",
        "    ranked_scores = tf.gather(predicted_ratings, sorted_indices).numpy().flatten()\n",
        "\n",
        "    print(f\"Ranked Recommendations for user {user_id_str}:\")\n",
        "    for title, score in zip(ranked_movie_titles, ranked_scores):\n",
        "        print(f\"  {title.decode('utf-8')}: {score:.4f}\")"
      ],
      "metadata": {
        "id": "9s2GySRin8ql"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "get_ranked_recommendations(\"42\", retrieved_candidates_scann)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7MZY6_hoWQa",
        "outputId": "941a6a14-3a6b-4fd6-d881-de09e4892f43"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked Recommendations for user 42:\n",
            "  Fried Green Tomatoes (1991): 4.5286\n",
            "  Circle of Friends (1995): 4.4630\n",
            "  Rudy (1993): 4.3066\n",
            "  Old Yeller (1957): 4.2954\n",
            "  Client, The (1994): 4.1300\n",
            "  Man Without a Face, The (1993): 4.1003\n",
            "  Bridges of Madison County, The (1995): 4.0771\n",
            "  Legends of the Fall (1994): 4.0558\n",
            "  Angels in the Outfield (1994): 3.8697\n",
            "  Kid in King Arthur's Court, A (1995): 3.6645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary:\n",
        "\n",
        "- **Retrieval Model**: Quickly narrows down the vast movie catalog to a manageable set of candidates using efficient embeddings.\n",
        "\n",
        "\n",
        "- **ScaNN Integration**: The movie embeddings from the retrieval model are indexed by ScaNN for fast approximate nearest neighbor search, making the candidate generation step even faster, especially for large item sets.\n",
        "\n",
        "\n",
        "- **Ranking Model**: Takes the retrieved candidates (now efficiently sourced via ScaNN) and uses more features (or more complex interactions) to predict a score (like a rating) for each, then orders them to produce the final recommendations."
      ],
      "metadata": {
        "id": "AAViaTReoe4A"
      }
    }
  ]
}